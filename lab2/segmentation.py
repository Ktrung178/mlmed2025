# -*- coding: utf-8 -*-
"""HC18 copy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o8ZxIhW6HlkBiJpmvDyZyME8VnEGLSp9
"""

import cv2
import os
import matplotlib.pyplot as plt
import pandas as pd

train_pixel_file = pd.read_csv('D:\\python\\lab2\\training_set_pixel_size_and_HC.csv')
train_pixel_file.head()

fig = plt.figure(figsize = (30,7))
for index in range(7):
  file_path = os.path.join('D:\\python\\lab2\\training_set\\training_set', train_pixel_file.iloc[index, 0].replace('.png','_Annotation.png'))

  ax = fig.add_subplot(2, 7, index+1)
  plt.imshow(cv2.imread(file_path))

  ax = fig.add_subplot(2, 7, index+8)

  plt.imshow(cv2.imread(file_path))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from skimage import io, color
from PIL import Image
import cv2

import os
import random

import torch
from torch.utils.data  import Dataset, DataLoader
from torchvision import transforms
import torchvision.transforms.functional as TF
import torch.nn as nn
import torch.nn.functional as F
import torchvision

validation_set_size = 0.20

class HC18(Dataset):

    def __init__(self, root_dir, train = True, transformX = None, transformY = None):
        self.pixel_file = pd.read_csv(os.path.join(root_dir, 'D:\\python\\lab2\\training_set_pixel_size_and_HC.csv'))
        self.root_dir = root_dir
        self.transformX = transformX
        self.transformY = transformY
        self.train = train


        self.train_data, self.validation_data = train_test_split(self.pixel_file, test_size = validation_set_size, random_state = 5)

    def __len__(self):

        if self.train:
          length = len(self.train_data)
        else:
          length = len(self.validation_data)
        return length

    def __getitem__(self, index):

        if self.train:
          imx_name = os.path.join(self.root_dir, self.train_data.iloc[index, 0])
          imy_name = os.path.join(self.root_dir,self.train_data.iloc[index, 0].replace('.png','_Annotation.png'))
        else:
          imx_name = os.path.join(self.root_dir, self.validation_data.iloc[index, 0])
          imy_name = os.path.join(self.root_dir,self.validation_data.iloc[index, 0].replace('.png','_Annotation.png'))


        imx = Image.open(imx_name)
        imy = Image.open(imy_name).convert('L')


        if self.train:

          if random.random() > 0.5:
              imx = TF.hflip(imx)
              imy = TF.hflip(imy)


          if random.random() > 0.5:
              imx = TF.vflip(imx)
              imy = TF.vflip(imy)



          if random.random() > 0.8:
            angle = random.choice([-30, -90, -60, -45 -15, 0, 15, 30, 45, 60, 90])
            imx = TF.rotate(imx, angle)
            imy = TF.rotate(imy, angle)





        if self.transformX :
            imx = self.transformX(imx)
            imy = self.transformY(imy)

        sample = {'image': imx, 'annotation': imy}
        return sample

tx_X = transforms.Compose([ transforms.Resize((572, 572)),
                              transforms.ToTensor(),
                              transforms.Normalize((0.5,), (0.5,))
                              ])
tx_Y = transforms.Compose([ transforms.Resize((572, 572)),
                              transforms.ToTensor(),
                              ])

train_data = HC18('D:\\python\\lab2\\training_set\\training_set', train = True, transformX = tx_X, transformY = tx_Y)
validation_data = HC18('D:\\python\\lab2\\training_set\\training_set', train = False, transformX = tx_X, transformY = tx_Y )

train_loader = DataLoader(dataset = train_data, batch_size = 4, shuffle = True, num_workers = 0 )
validation_loader = DataLoader(dataset = validation_data, batch_size = 4, shuffle = True, num_workers = 0)

def im_converterX(tensor):
    image = tensor.cpu().clone().detach().numpy()
    image = image.transpose(1,2,0)
    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))
    image = image.clip(0, 1)
    return image

def im_converterY(tensor):
    image = tensor.cpu().clone().detach().numpy()
    image = image.transpose(1,2,0)
    image = image * np.array((1, 1, 1))
    image = image.clip(0, 1)
    return image

fig = plt.figure(figsize = (15,6))
for ith_batch, sample_batched in enumerate(train_loader):
    print(ith_batch, sample_batched['image'].size(), sample_batched['annotation'].size())

    for index in range(2):
        ax = fig.add_subplot(2, 2 , index + 1)
        plt.imshow(im_converterX(sample_batched['image'][index]))
        ax = fig.add_subplot(2, 2, index + 3)
        plt.imshow(im_converterY(sample_batched['annotation'][index]))
    break

class double_conv(nn.Module):


    def __init__(self, in_ch, out_ch):
        super(double_conv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        x = self.conv(x)
        return x


class inconv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(inconv, self).__init__()
        self.conv = double_conv(in_ch, out_ch)

    def forward(self, x):
        x = self.conv(x)
        return x


class down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(down, self).__init__()
        self.mpconv = nn.Sequential(
            nn.MaxPool2d(2),
            double_conv(in_ch, out_ch)
        )

    def forward(self, x):
        x = self.mpconv(x)
        return x


class up(nn.Module):
    def __init__(self, in_ch, out_ch, bilinear=True):
        super(up, self).__init__()

        if bilinear:
            self.up = nn.Upsample(
                scale_factor=2, mode='bilinear', align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)

        self.conv = double_conv(in_ch, out_ch)

    def forward(self, x1, x2):
        x1 = self.up(x1)


        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2))

        x = torch.cat([x2, x1], dim=1)
        x = self.conv(x)
        return x

class outconv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(outconv, self).__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 1)

    def forward(self, x):
        x = self.conv(x)
        return x
class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        self.inc = inconv(n_channels, 64)
        self.down1 = down(64, 128)
        self.down2 = down(128, 256)
        self.down3 = down(256, 512)
        self.down4 = down(512, 512)
        self.up1 = up(1024, 256, bilinear = False)
        self.up2 = up(512, 128, bilinear = False)
        self.up3 = up(256, 64, bilinear = False)
        self.up4 = up(128, 64, bilinear = False)
        self.outc = outconv(64, n_classes)
        self.dropout = torch.nn.Dropout2d(0.5)

    def forward(self, x):
        x = x.float()
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.dropout(x)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        return torch.sigmoid(x)

model = UNet(1, 1)
model.to('cuda')
print("Model Loaded to GPU")
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr = 0.0077)

def dice_index(y_pred, y_actual):
    smooth = 0.000001
    size_of_batch = y_pred.size(0)

    p1 = y_pred.view(size_of_batch, -1)
    p2 = y_actual.view(size_of_batch, -1)

    intersection = (p1 * p2).sum()

    dice =  ((2.0 * intersection )+ smooth) / (p1.sum() + p2.sum() + smooth)


    return dice

def dice_loss(y_predict, y_train):

  dice_loss = 1 -(dice_index(y_predict, y_train))

  return dice_loss

def dice_index(y_pred, y_actual):
    smooth = 0.000001
    size_of_batch = y_pred.size(0)
    p1 = y_pred.view(size_of_batch, -1)
    p2 = y_actual.view(size_of_batch, -1)
    intersection = (p1 * p2).sum()
    dice =  ((2.0 * intersection )+ smooth) / (p1.sum() + p2.sum() + smooth)
    return dice.item()

def pixel_accuracy(y_pred, y_actual):
    with torch.no_grad():
        y_pred_binary = (y_pred > 0.5).float()
        correct_pixels = (y_pred_binary == y_actual).sum()
        total_pixels = y_actual.numel()
        accuracy = correct_pixels / total_pixels
    return accuracy.item()

def iou_score(y_pred, y_actual):
    with torch.no_grad():
        y_pred_binary = (y_pred > 0.5).float()
        intersection = (y_pred_binary * y_actual).sum()
        union = (y_pred_binary + y_actual).sum() - intersection
        iou = (intersection + 1e-6) / (union + 1e-6)
    return iou.item()

epochs = 20

train_running_loss_history = []
validation_running_loss_history =[]
train_accuracy_history = []
validation_accuracy_history = []
train_iou_history = []
validation_iou_history = []
train_dice_history = []
validation_dice_history = []


for e in range(epochs):
  train_running_loss = 0.0
  validation_running_loss = 0.0
  train_running_accuracy = 0.0
  validation_running_accuracy = 0.0
  train_running_iou = 0.0
  validation_running_iou = 0.0
  train_running_dice = 0.0
  validation_running_dice = 0.0


  model.train()

  for ith_batch, sample_batched in enumerate(train_loader):
    X_train = sample_batched['image'].to('cuda')
    y_train = sample_batched['annotation'].to('cuda')

    optimizer.zero_grad()
    y_pred = model(X_train)

    loss = 0.30 * (1 - dice_index(y_pred, y_train)) +  0.70 * criterion(y_pred, y_train)
    loss.backward()
    optimizer.step()

    train_running_loss += loss.item()
    train_running_accuracy += pixel_accuracy(y_pred, y_train)
    train_running_iou += iou_score(y_pred, y_train)
    train_running_dice += dice_index(y_pred, y_train)


    if ith_batch % 50 == 0:
      print(f'Epoch: {e + 1}, Batch: {ith_batch}, Loss: {loss.item():.4f}, Acc: {pixel_accuracy(y_pred, y_train):.4f}, IoU: {iou_score(y_pred, y_train):.4f}, Dice: {dice_index(y_pred, y_train):.4f}')


  else:
    with torch.no_grad():
      model.eval()
      for ith_batch, sample_batched in enumerate(validation_loader):
          X_val = sample_batched['image'].to('cuda')
          y_val = sample_batched['annotation'].to('cuda')
          y_out = model(X_val)
          out_val = (y_out + 0.5).int().float()

          val_loss = 0.3 * (1 - dice_index(out_val, y_val))  + 0.7 * criterion(y_out, y_val)
          validation_running_loss += val_loss.item()
          validation_running_accuracy += pixel_accuracy(y_out, y_val)
          validation_running_iou += iou_score(y_out, y_val)
          validation_running_dice += dice_index(y_out, y_val)


      print("================================================================================")
      print(f"Epoch {e + 1} completed")

      train_epoch_loss = train_running_loss / len(train_loader)
      validation_epoch_loss = validation_running_loss / len(validation_loader)
      train_epoch_accuracy = train_running_accuracy / len(train_loader)
      validation_epoch_accuracy = validation_running_accuracy / len(validation_loader)
      train_epoch_iou = train_running_iou / len(train_loader)
      validation_epoch_iou = validation_running_iou / len(validation_loader)
      train_epoch_dice = train_running_dice / len(train_loader)
      validation_epoch_dice = validation_running_dice / len(validation_loader)


      print(f"Avg Train Loss: {train_epoch_loss:.4f}, Avg Val Loss: {validation_epoch_loss:.4f}")
      print(f"Avg Train Acc: {train_epoch_accuracy:.4f}, Avg Val Acc: {validation_epoch_accuracy:.4f}")
      print(f"Avg Train IoU: {train_epoch_iou:.4f}, Avg Val IoU: {validation_epoch_iou:.4f}")
      print(f"Avg Train Dice: {train_epoch_dice:.4f}, Avg Val Dice: {validation_epoch_dice:.4f}")

      print("================================================================================")
      train_running_loss_history.append(train_epoch_loss)
      validation_running_loss_history.append(validation_epoch_loss)
      train_accuracy_history.append(train_epoch_accuracy)
      validation_accuracy_history.append(validation_epoch_accuracy)
      train_iou_history.append(train_epoch_iou)
      validation_iou_history.append(validation_epoch_iou)
      train_dice_history.append(train_epoch_dice)
      validation_dice_history.append(validation_epoch_dice)


  torch.cuda.empty_cache()

plt.plot(train_running_loss_history, label = 'Train Loss')
plt.plot(validation_running_loss_history, label = 'Validation Loss')
plt.legend()
model.eval()
X_train.size()

class HC18_test(Dataset):
    def __init__(self, root_dir, transformX = None):
        self.pixel_file = pd.read_csv(os.path.join(root_dir, 'D:\\python\\lab2\\test_set_pixel_size.csv'))
        self.root_dir = root_dir
        self.transformX = transformX

    def __len__(self):
        return len(self.pixel_file)

    def __getitem__(self, index):
        imx_name = os.path.join(self.root_dir, self.pixel_file.iloc[index, 0])

        imx = Image.open(imx_name)

        f_name = self.pixel_file.iloc[index, 0]

        if self.transformX :
            imx = self.transformX(imx)

        sample = {'image': imx, 'f_name': f_name}
        return sample

test_data = HC18_test('D:\\python\\lab2\\test_set\\test_set', transformX = tx_X)
test_loader = DataLoader(dataset = test_data, batch_size = 2, shuffle = True)

fig = plt.figure(figsize = (15,6))

for ith_batch, sample_batched in enumerate(test_loader):

    X_test = sample_batched['image'].to('cuda')
    print(ith_batch, X_test.size())

    y_test = (model(X_test) + 0.5).int().float()


    for index in range(2):
        ax = fig.add_subplot(2, 2 , index + 1)
        plt.imshow(im_converterX(X_test[index]))

        ax  = fig.add_subplot(2, 2, index + 3)
        plt.imshow(im_converterY(y_test[index]))
    break